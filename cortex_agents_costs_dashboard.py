# Import python packages
import streamlit as st
import pandas as pd
import datetime
import json
import plotly.express as px
import plotly.graph_objects as go
from snowflake.snowpark.context import get_active_session

# Set page configuration
st.set_page_config(
    page_title="Snowflake Intelligence Cost Dashboard",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #29B5E8, #11567F);
        padding: 2rem 1rem 1rem 1rem;
        border-radius: 0.5rem;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    
    .main-title {
        font-family: Arial, sans-serif;
        font-weight: bold;
        font-size: 2.5rem;
        color: white;
        margin: 0;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }
</style>
""", unsafe_allow_html=True)

# Header
header_html = """
<div class="main-header">
    <h1 class="main-title">ðŸ¤– SNOWFLAKE INTELLIGENCE COST DASHBOARD</h1>
    <div style="font-size: 1.1rem; opacity: 0.9;">
        Monitor and analyze costs for all Cortex Agents used in your Snowflake account
    </div>
</div>
"""
st.markdown(header_html, unsafe_allow_html=True)

# Get the current credentials
session = get_active_session()

@st.cache_data
def get_snowflake_edition():
    """Get Snowflake edition for cost estimation"""
    try:
        edition_query = """
        SELECT edition
        FROM SNOWFLAKE.ORGANIZATION_USAGE.ACCOUNTS
        WHERE account_name = CURRENT_ACCOUNT_NAME()
        """
        result = session.sql(edition_query).collect()
        if result:
            return result[0]['EDITION']
        return 'STANDARD'
    except Exception:
        return 'STANDARD'

def get_cost_per_credit(edition):
    """Get estimated cost per credit based on edition"""
    costs = {
        'STANDARD': 2.60,
        'ENTERPRISE': 3.90,
        'BUSINESS_CRITICAL': 5.20
    }
    return costs.get(edition.upper(), 2.60)

def format_cost(credits, cost_per_credit):
    """Format cost for display"""
    cost = credits * cost_per_credit
    if cost == 0:
        return "$0.00"
    elif cost < 0.01:
        return f"${cost:.4f}"
    else:
        return f"${cost:.2f}"

def format_credits(credits):
    """Format credits for display"""
    if credits == 0:
        return "0.000"
    elif credits < 0.001:
        return f"{credits:.6f}"
    elif credits < 1:
        return f"{credits:.3f}"
    else:
        return f"{credits:.2f}"

@st.cache_data
def get_warehouse_costs_breakdown(days):
    """Get warehouse costs breakdown for cortex vs non-cortex queries - performance optimized"""
    cost_query = f"""
    WITH cortex_warehouses AS (
      -- Step 1: Quickly identify warehouses with Cortex Analyst activity
      SELECT DISTINCT warehouse_name
      FROM snowflake.account_usage.query_history
      WHERE start_time >= DATEADD(DAY, -{days}, CURRENT_DATE)
        AND warehouse_name IS NOT NULL
        AND query_text LIKE '%Generated by Cortex Analyst%'
    ), filtered_queries AS (
      -- Step 2: Get only queries from relevant warehouses (much smaller dataset)
      SELECT
        query_id,
        warehouse_name,
        CASE WHEN query_text LIKE '%Generated by Cortex Analyst%' THEN 1 ELSE 0 END AS is_cortex_query
      FROM snowflake.account_usage.query_history
      WHERE start_time >= DATEADD(DAY, -{days}, CURRENT_DATE)
        AND warehouse_name IN (SELECT warehouse_name FROM cortex_warehouses)
    ), query_with_credits AS (
      -- Step 3: Join credits only for the filtered set (small join)
      SELECT
        fq.warehouse_name,
        fq.is_cortex_query,
        COALESCE(qa.credits_attributed_compute, 0) + COALESCE(qa.credits_used_query_acceleration, 0) AS total_credits
      FROM filtered_queries fq
      INNER JOIN snowflake.account_usage.query_attribution_history qa ON fq.query_id = qa.query_id
    )
    SELECT
      warehouse_name,
      CASE WHEN is_cortex_query = 1 THEN 'Cortex Analyst' ELSE 'Other Queries' END AS query_type,
      COUNT(*) AS query_count,
      SUM(total_credits) AS total_credits
    FROM query_with_credits
    GROUP BY warehouse_name, is_cortex_query
    ORDER BY warehouse_name, is_cortex_query DESC
    """
    
    try:
        result = session.sql(cost_query).to_pandas()
        return result
    except Exception as e:
        st.error(f"Could not fetch warehouse cost data: {str(e)}")
        return pd.DataFrame()

@st.cache_data  
def get_cortex_analyst_usage(days):
    """Get Cortex Analyst usage history"""
    usage_query = f"""
    SELECT
      START_TIME,
      END_TIME,
      REQUEST_COUNT,
      CREDITS,
      USERNAME
    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_ANALYST_USAGE_HISTORY
    WHERE START_TIME >= DATEADD(DAY, -{days}, CURRENT_DATE)
    ORDER BY START_TIME DESC
    """
    
    try:
        result = session.sql(usage_query).to_pandas()
        return result
    except Exception as e:
        st.error(f"Could not fetch Cortex Analyst usage data: {str(e)}")
        return pd.DataFrame()

@st.cache_data
def get_cortex_analyst_requests(days):
    """Get Cortex Analyst requests"""
    requests_query = f"""
    SELECT
      timestamp,
      semantic_model_name,
      user_name,
      latest_question,
      feedback
    FROM snowflake.local.CORTEX_ANALYST_REQUESTS_V
    WHERE timestamp >= DATEADD(DAY, -{days}, CURRENT_DATE)
    ORDER BY timestamp DESC
    LIMIT 1000
    """
    
    try:
        result = session.sql(requests_query).to_pandas()
        return result
    except Exception as e:
        st.error(f"Could not fetch Cortex Analyst requests data: {str(e)}")
        return pd.DataFrame()

@st.cache_data
def get_agents():
    """Get available Cortex Agents"""
    try:
        agents_data = session.sql("""
            SHOW AGENTS IN SCHEMA SNOWFLAKE_INTELLIGENCE.AGENTS
        """).to_pandas()
        return agents_data
    except Exception as e:
        st.error(f"Error fetching agents: {str(e)}")
        return pd.DataFrame()

@st.cache_data
def get_agent_details(agent_name):
    """Get detailed agent information including tools"""
    try:
        describe_query = f"DESCRIBE AGENT SNOWFLAKE_INTELLIGENCE.AGENTS.{agent_name}"
        agent_details = session.sql(describe_query).to_pandas()
        
        if not agent_details.empty:
            # Parse the agent_spec JSON to find tools
            agent_spec_col = list(agent_details.columns)[6]  # agent_spec is typically at index 6
            agent_spec_json = agent_details.iloc[0][agent_spec_col]
            
            if agent_spec_json:
                try:
                    spec = json.loads(agent_spec_json)
                    
                    # Extract all tools info
                    tools_info = {
                        'cortex_analyst_tools': [],
                        'cortex_search_services': []
                    }
                    
                    if 'tools' in spec:
                        for tool in spec['tools']:
                            if 'tool_spec' in tool:
                                tool_spec = tool['tool_spec']
                                tool_type = tool_spec.get('type')
                                tool_name = tool_spec.get('name', 'Unknown')
                                
                                if tool_type == 'cortex_analyst_text_to_sql':
                                    # Get warehouse and semantic view
                                    warehouse = 'Not specified'
                                    semantic_view = 'Not specified'
                                    
                                    if 'tool_resources' in spec and tool_name in spec['tool_resources']:
                                        tool_resource = spec['tool_resources'][tool_name]
                                        semantic_view = tool_resource.get('semantic_view', 'Not specified')
                                        
                                        if 'execution_environment' in tool_resource:
                                            exec_env = tool_resource['execution_environment']
                                            if exec_env.get('type') == 'warehouse':
                                                warehouse = exec_env.get('warehouse', 'Not specified')
                                    
                                    tools_info['cortex_analyst_tools'].append({
                                        'name': tool_name,
                                        'warehouse': warehouse,
                                        'semantic_view': semantic_view
                                    })
                                
                                elif tool_type == 'cortex_search':
                                    # Extract Cortex Search service info
                                    search_service = tool_spec.get('search_service', 'Unknown')
                                    tools_info['cortex_search_services'].append({
                                        'name': tool_name,
                                        'search_service': search_service
                                    })
                    
                    return tools_info
                    
                except json.JSONDecodeError:
                    return {'cortex_analyst_tools': [], 'cortex_search_services': []}
        
        return {'cortex_analyst_tools': [], 'cortex_search_services': []}
    except Exception as e:
        st.error(f"Error getting agent details: {str(e)}")
        return {'cortex_analyst_tools': [], 'cortex_search_services': []}

@st.cache_data
def get_cortex_search_usage(days):
    """Get Cortex Search usage history"""
    search_query = f"""
    SELECT
      USAGE_DATE,
      DATABASE_NAME,
      SCHEMA_NAME,
      SERVICE_NAME,
      SERVICE_ID,
      CONSUMPTION_TYPE,
      CREDITS,
      MODEL_NAME,
      TOKENS
    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_SEARCH_DAILY_USAGE_HISTORY
    WHERE USAGE_DATE >= DATEADD(DAY, -{days}, CURRENT_DATE)
    ORDER BY USAGE_DATE DESC, CREDITS DESC
    """
    
    try:
        result = session.sql(search_query).to_pandas()
        return result
    except Exception as e:
        st.error(f"Could not fetch Cortex Search usage data: {str(e)}")
        return pd.DataFrame()

# Initialize session state and configuration
if 'initialized' not in st.session_state:
    st.session_state.initialized = True

# Get Snowflake edition for cost estimation
edition = get_snowflake_edition()
cost_per_credit = get_cost_per_credit(edition)

# Sidebar configuration
st.sidebar.header("âš™ï¸ Configuration")

# Display/cost toggle
display_mode = st.sidebar.radio(
    "Display Mode:",
    ["Credits", "Estimated Cost"],
    help=f"Toggle between credits and estimated cost based on {edition} edition"
)

# Edition info
with st.sidebar.expander("ðŸ’¡ Cost Estimation Details", expanded=False):
    st.write(f"**Snowflake Edition:** {edition}")
    st.write(f"**Cost per Credit:** ${cost_per_credit:.2f}")
    st.write("**Note:** Costs are estimates based on typical pricing.")
    st.write("**Actual costs may vary based on your specific contract.**")

# Main content area
st.subheader("ðŸ’° Snowflake Intelligence Cost Analysis")
st.info("ðŸ“‹ **Note:** This dashboard now covers Cortex Analyst, Warehouse, and Cortex Search costs!")

# Expandable info section
with st.expander("ðŸ“š Learn more about Snowflake Intelligence costs", expanded=False):
    st.markdown("""
    **Total costs for Snowflake Intelligence is derived from three main components in a pure consumption-based model:**
    
    1. **ðŸŽ¯ Token usage** - charged per million tokens for both input tokens (context and data the agent processes) and output tokens (the agent's responses, queries, and SQL statements)
    
    2. **ðŸ” Cortex Search costs** - consumption charges based on the size of knowledge base indexes when the agent accesses internal company data *(not included in this dashboard)*
    
    3. **ðŸ­ Warehouse compute costs** - standard Snowflake warehouse charges when the agent executes queries to answer questions
    
    ---
    
    **ðŸ“Š This dashboard covers all 3 components:**
    - **Cortex Analyst Usage**: Token consumption for text-to-SQL generation
    - **Cortex Search Costs**: Consumption for knowledge base services used by agents
    - **Warehouse Costs**: Compute costs for executing generated queries
    """)

# Create tabs for different time periods and data views
tab7, tab1, tab3, tab30, tab_agents, tab_search, tab5, tab6 = st.tabs([
    "ðŸ“… 7 Days", "ðŸ“… 1 Day", "ðŸ“… 3 Days", "ðŸ“… 30 Days",
    "ðŸ¤– All Agents", "ðŸ” Cortex Search", "ðŸ“Š Cortex Analyst Usage", "ðŸ“‹ Raw Requests Data"
])

# Function to render period tab content
def render_period_tab(days, period_name, display_mode, cost_per_credit):
    st.markdown(f"### ðŸ“Š Costs for Last {period_name}")
    
    # Get data
    warehouse_data = get_warehouse_costs_breakdown(days)
    cortex_usage_data = get_cortex_analyst_usage(days)
    
    # Calculate totals
    warehouse_cortex_credits = 0
    warehouse_other_credits = 0
    cortex_analyst_credits = cortex_usage_data['CREDITS'].sum() if not cortex_usage_data.empty else 0
    
    if not warehouse_data.empty:
        cortex_mask = warehouse_data['QUERY_TYPE'] == 'Cortex Analyst'
        other_mask = warehouse_data['QUERY_TYPE'] == 'Other Queries'
        warehouse_cortex_credits = warehouse_data[cortex_mask]['TOTAL_CREDITS'].sum()
        warehouse_other_credits = warehouse_data[other_mask]['TOTAL_CREDITS'].sum()
    
    total_cortex_credits = warehouse_cortex_credits + cortex_analyst_credits
    
    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        value = total_cortex_credits
        display_value = format_credits(value) if display_mode == "Credits" else format_cost(value, cost_per_credit)
        st.metric(
            f"ðŸ’° Total Snowflake Intelligence {'Credits' if display_mode == 'Credits' else 'Cost'}",
            display_value,
            help="Total credits/cost for SQL queries + Cortex Analyst usage"
        )
    
    with col2:
        value = cortex_analyst_credits
        display_value = format_credits(value) if display_mode == "Credits" else format_cost(value, cost_per_credit)
        st.metric(
            f"ðŸ¤– Cortex Analyst {'Credits' if display_mode == 'Credits' else 'Cost'}",
            display_value,
            help="Credits/cost for text-to-SQL generation"
        )
    
    with col3:
        value = warehouse_cortex_credits
        display_value = format_credits(value) if display_mode == "Credits" else format_cost(value, cost_per_credit)
        st.metric(
            f"ðŸ­ Warehouse {'Credits' if display_mode == 'Credits' else 'Cost'}",
            display_value,
            help="Credits/cost for the SQL query execution"
        )
    
    with col4:
        cortex_queries = warehouse_data[warehouse_data['QUERY_TYPE'] == 'Cortex Analyst']['QUERY_COUNT'].sum() if not warehouse_data.empty else 0
        st.metric(
            "ðŸ” Cortex Analyst Queries",
            f"{cortex_queries:,}",
            help="Number of queries executed by Cortex Analyst"
        )
    
    # Warehouse breakdown chart and table - only show warehouses with Cortex Analyst activity
    if not warehouse_data.empty:
        # Prepare data for stacked bar chart and filter for warehouses with Cortex Analyst activity
        pivot_data = warehouse_data.pivot(index='WAREHOUSE_NAME', columns='QUERY_TYPE', values='TOTAL_CREDITS').fillna(0)
        
        # Only keep warehouses that have Cortex Analyst credits > 0
        if 'Cortex Analyst' in pivot_data.columns:
            cortex_warehouses = pivot_data[pivot_data['Cortex Analyst'] > 0]
            
            if not cortex_warehouses.empty:
                st.markdown("#### ðŸ“ˆ Warehouse Credits Breakdown")
                
                fig = go.Figure()
                
                # Prepare y-values based on display mode
                cortex_y_values = cortex_warehouses['Cortex Analyst']
                other_y_values = cortex_warehouses['Other Queries'] if 'Other Queries' in cortex_warehouses.columns else pd.Series([0]*len(cortex_warehouses))
                
                if display_mode == "Estimated Cost":
                    cortex_y_values = cortex_y_values * cost_per_credit
                    other_y_values = other_y_values * cost_per_credit
                
                fig.add_trace(go.Bar(
                    name='Cortex Analyst',
                    x=cortex_warehouses.index,
                    y=cortex_y_values,
                    marker_color='#29B5E8'
                ))
                
                if 'Other Queries' in cortex_warehouses.columns:
                    fig.add_trace(go.Bar(
                        name='Other Queries',
                        x=cortex_warehouses.index,
                        y=other_y_values,
                        marker_color='#11567F'
                    ))
                
                fig.update_layout(
                    title=f"Warehouse Usage Breakdown - Last {period_name}",
                    xaxis_title="Warehouse",
                    yaxis_title="Credits Used" if display_mode == "Credits" else "Estimated Cost ($)",
                    barmode='stack',
                    font_family="Arial"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Detailed breakdown table - one row per warehouse
                st.markdown("#### ðŸ“‹ Detailed Warehouse Breakdown")
                
                # Create table with one row per warehouse and separate columns
                table_data = []
                for warehouse in cortex_warehouses.index:
                    cortex_credits = cortex_warehouses.loc[warehouse, 'Cortex Analyst']
                    other_credits = cortex_warehouses.loc[warehouse, 'Other Queries'] if 'Other Queries' in cortex_warehouses.columns else 0
                    
                    # Get query counts
                    cortex_queries_count = warehouse_data[
                        (warehouse_data['WAREHOUSE_NAME'] == warehouse) & 
                        (warehouse_data['QUERY_TYPE'] == 'Cortex Analyst')
                    ]['QUERY_COUNT'].iloc[0] if len(warehouse_data[
                        (warehouse_data['WAREHOUSE_NAME'] == warehouse) & 
                        (warehouse_data['QUERY_TYPE'] == 'Cortex Analyst')
                    ]) > 0 else 0
                    
                    other_queries_count = warehouse_data[
                        (warehouse_data['WAREHOUSE_NAME'] == warehouse) & 
                        (warehouse_data['QUERY_TYPE'] == 'Other Queries')
                    ]['QUERY_COUNT'].iloc[0] if len(warehouse_data[
                        (warehouse_data['WAREHOUSE_NAME'] == warehouse) & 
                        (warehouse_data['QUERY_TYPE'] == 'Other Queries')
                    ]) > 0 else 0
                    
                    if display_mode == "Credits":
                        table_data.append({
                            'WAREHOUSE_NAME': warehouse,
                            'CORTEX_ANALYST_CREDITS': format_credits(cortex_credits),
                            'OTHER_CREDITS': format_credits(other_credits),
                            'CORTEX_ANALYST_QUERIES': cortex_queries_count,
                            'OTHER_QUERIES': other_queries_count
                        })
                    else:
                        table_data.append({
                            'WAREHOUSE_NAME': warehouse,
                            'CORTEX_ANALYST_COST': format_cost(cortex_credits, cost_per_credit),
                            'OTHER_COST': format_cost(other_credits, cost_per_credit),
                            'CORTEX_ANALYST_QUERIES': cortex_queries_count,
                            'OTHER_QUERIES': other_queries_count
                        })
                
                table_df = pd.DataFrame(table_data)
                st.dataframe(table_df, use_container_width=True, hide_index=True)
                
            else:
                st.info(f"ðŸ’¡ No Cortex Analyst activity found for the last {period_name}.")
        else:
            st.info(f"ðŸ’¡ No Cortex Analyst activity found for the last {period_name}.")
    else:
        st.info(f"ðŸ’¡ No warehouse activity found for the last {period_name}.")
    
    # Cortex Analyst usage summary
    if not cortex_usage_data.empty:
        st.markdown("#### ðŸ¤– Cortex Analyst Usage Summary")
        col1, col2 = st.columns(2)
        
        with col1:
            total_requests = cortex_usage_data['REQUEST_COUNT'].sum()
            st.metric("Total Requests", f"{total_requests:,}")
        
        with col2:
            unique_users = cortex_usage_data['USERNAME'].nunique()
            st.metric("Unique Users", str(unique_users))

# Render period tabs
with tab7:
    render_period_tab(7, "7 Days", display_mode, cost_per_credit)

with tab1:
    render_period_tab(1, "1 Day", display_mode, cost_per_credit)

with tab3:
    render_period_tab(3, "3 Days", display_mode, cost_per_credit)

with tab30:
    render_period_tab(30, "30 Days", display_mode, cost_per_credit)

# All Agents Tab
with tab_agents:
    st.markdown("### ðŸ¤– All Cortex Agents in Account")
    
    agents_data = get_agents()
    
    if not agents_data.empty:
        st.write(f"**Total Agents Found:** {len(agents_data)}")
        
        # Get the actual column names
        columns = list(agents_data.columns)
        name_col = columns[1] if len(columns) > 1 else columns[0]
        
        # Agent details expansion
        for _, agent_row in agents_data.iterrows():
            agent_name = agent_row[name_col]
            
            with st.expander(f"ðŸ¤– Agent: {agent_name}", expanded=False):
                # Basic agent info
                if len(columns) > 5:
                    comment_col = columns[5]  # 'comment' is at index 5
                    created_col = columns[0]  # 'created_on' is at index 0
                    owner_col = columns[4]    # 'owner' is at index 4
                    
                    comment = agent_row[comment_col]
                    if pd.isna(comment) or not str(comment).strip():
                        comment = 'No description available'
                    st.write(f"**Description:** {comment}")
                    
                    # Convert timestamp to readable date
                    try:
                        created_timestamp = float(agent_row[created_col])
                        created_date = datetime.datetime.fromtimestamp(created_timestamp)
                        st.write(f"**Created:** {created_date.strftime('%Y-%m-%d %H:%M:%S')}")
                    except:
                        st.write(f"**Created:** {agent_row[created_col]}")
                    
                    st.write(f"**Owner:** {agent_row[owner_col]}")
                
                # Get detailed tool configuration
                tools_info = get_agent_details(agent_name)
                
                if tools_info['cortex_analyst_tools']:
                    st.markdown("**ðŸ” Cortex Analyst Tools:**")
                    for i, tool in enumerate(tools_info['cortex_analyst_tools'], 1):
                        st.write(f"  {i}. **{tool['name']}** - Warehouse: `{tool['warehouse']}`, View: `{tool['semantic_view']}`")
                
                if tools_info['cortex_search_services']:
                    st.markdown("**ðŸ” Cortex Search Services:**")
                    for i, service in enumerate(tools_info['cortex_search_services'], 1):
                        st.write(f"  {i}. **{service['name']}** - Service: `{service['search_service']}`")
                
                if not tools_info['cortex_analyst_tools'] and not tools_info['cortex_search_services']:
                    st.info("No Cortex tools configured for this agent.")
        
        # Show all agents table
        st.markdown("#### ðŸ“‹ All Agents Summary")
        st.dataframe(agents_data, use_container_width=True, hide_index=True)
        
    else:
        st.warning("No Cortex Agents found in your account.")
        st.info("Ensure you have agents deployed in the SNOWFLAKE_INTELLIGENCE.AGENTS schema.")

# Cortex Search Costs Tab
with tab_search:
    st.markdown("### ðŸ” Cortex Search Cost Analysis")
    
    period_days = st.selectbox("Select Time Period:", [7, 1, 3, 30], index=0, key="search_period")
    
    # Get search usage data
    search_usage_data = get_cortex_search_usage(period_days)
    agents_data = get_agents()
    
    if not search_usage_data.empty:
        # Get all agent search services for matching
        all_agent_search_services = set()
        agent_service_mapping = {}
        
        if not agents_data.empty:
            columns = list(agents_data.columns)
            name_col = columns[1] if len(columns) > 1 else columns[0]
            
            for _, agent_row in agents_data.iterrows():
                agent_name = agent_row[name_col]
                tools_info = get_agent_details(agent_name)
                
                for service in tools_info['cortex_search_services']:
                    service_name = service['search_service']
                    all_agent_search_services.add(service_name)
                    if service_name not in agent_service_mapping:
                        agent_service_mapping[service_name] = []
                    agent_service_mapping[service_name].append(agent_name)
        
        # Filter search usage to only show services used by agents
        agent_search_usage = search_usage_data[
            search_usage_data['SERVICE_NAME'].isin(all_agent_search_services)
        ] if all_agent_search_services else pd.DataFrame()
        
        # Calculate totals
        total_search_credits = agent_search_usage['CREDITS'].sum() if not agent_search_usage.empty else 0
        total_all_search_credits = search_usage_data['CREDITS'].sum()
        
        # Display metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            value = total_search_credits
            display_value = format_credits(value) if display_mode == "Credits" else format_cost(value, cost_per_credit)
            st.metric(
                f"ðŸ’° Agent Search {'Credits' if display_mode == 'Credits' else 'Cost'}",
                display_value,
                help="Cortex Search costs for services used by Cortex Agents"
            )
        
        with col2:
            value = total_all_search_credits
            display_value = format_credits(value) if display_mode == "Credits" else format_cost(value, cost_per_credit)
            st.metric(
                f"ðŸ” Total Search {'Credits' if display_mode == 'Credits' else 'Cost'}",
                display_value,
                help="Total Cortex Search costs (all services)"
            )
        
        with col3:
            unique_services = len(all_agent_search_services)
            st.metric(
                "ðŸ¤– Agent Services",
                str(unique_services),
                help="Number of Cortex Search services used by agents"
            )
        
        with col4:
            total_services = search_usage_data['SERVICE_NAME'].nunique()
            st.metric(
                "ðŸ“Š Total Services",
                str(total_services),
                help="Total number of Cortex Search services in account"
            )
        
        # Show agent-related search services
        if not agent_search_usage.empty:
            st.markdown("#### ðŸ¤– Search Services Used by Agents")
            
            # Group by service and show which agents use it
            service_breakdown = []
            for service_name in agent_search_usage['SERVICE_NAME'].unique():
                service_data = agent_search_usage[agent_search_usage['SERVICE_NAME'] == service_name]
                agents_using = agent_service_mapping.get(service_name, [])
                
                service_breakdown.append({
                    'SERVICE_NAME': service_name,
                    'AGENTS_USING': ', '.join(agents_using),
                    'TOTAL_CREDITS': service_data['CREDITS'].sum(),
                    'USAGE_DAYS': service_data['USAGE_DATE'].nunique()
                })
            
            breakdown_df = pd.DataFrame(service_breakdown)
            breakdown_df = breakdown_df.sort_values('TOTAL_CREDITS', ascending=False)
            
            # Format for display
            if display_mode == "Credits":
                breakdown_df['TOTAL_CREDITS'] = breakdown_df['TOTAL_CREDITS'].apply(format_credits)
            else:
                breakdown_df['TOTAL_COST'] = breakdown_df['TOTAL_CREDITS'].apply(lambda x: format_cost(x, cost_per_credit))
                breakdown_df = breakdown_df.drop('TOTAL_CREDITS', axis=1)
            
            st.dataframe(breakdown_df, use_container_width=True, hide_index=True)
            
            # Show raw data for agent services
            st.markdown("#### ðŸ“‹ Detailed Usage Data (Agent Services Only)")
            display_search = agent_search_usage.copy()
            if display_mode == "Cost":
                display_search['ESTIMATED_COST'] = display_search['CREDITS'].apply(lambda x: format_cost(x, cost_per_credit))
            else:
                display_search['CREDITS'] = display_search['CREDITS'].apply(format_credits)
            
            st.dataframe(display_search, use_container_width=True, hide_index=True)
        
        else:
            st.info("No Cortex Search services found that are used by your Cortex Agents.")
            st.markdown("#### ðŸ“Š All Search Services in Account")
            st.write(f"Total services found: {len(search_usage_data)}")
            
            # Show top search services
            if not search_usage_data.empty:
                top_services = search_usage_data.groupby('SERVICE_NAME')['CREDITS'].sum().reset_index()
                top_services = top_services.sort_values('CREDITS', ascending=False).head(10)
                
                if display_mode == "Credits":
                    top_services['CREDITS'] = top_services['CREDITS'].apply(format_credits)
                else:
                    top_services['ESTIMATED_COST'] = top_services['CREDITS'].apply(lambda x: format_cost(x, cost_per_credit))
                    top_services = top_services.drop('CREDITS', axis=1)
                
                st.dataframe(top_services, use_container_width=True, hide_index=True)
    
    else:
        st.info(f"No Cortex Search usage data found for the last {period_days} days.")

# Cortex Analyst Usage Tab
with tab5:
    st.markdown("### ðŸ¤– Cortex Analyst Usage Details")
    
    period_days = st.selectbox("Select Time Period:", [7, 1, 3, 30], index=0, key="usage_period")
    usage_data = get_cortex_analyst_usage(period_days)
    
    if not usage_data.empty:
        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_credits = usage_data['CREDITS'].sum()
            display_value = format_credits(total_credits) if display_mode == "Credits" else format_cost(total_credits, cost_per_credit)
            st.metric(f"Total {'Credits' if display_mode == 'Credits' else 'Cost'}", display_value)
        
        with col2:
            total_requests = usage_data['REQUEST_COUNT'].sum()
            st.metric("Total Requests", f"{total_requests:,}")
        
        with col3:
            unique_users = usage_data['USERNAME'].nunique()
            st.metric("Unique Users", str(unique_users))
        
        with col4:
            avg_credits_per_request = total_credits / total_requests if total_requests > 0 else 0
            display_value = format_credits(avg_credits_per_request) if display_mode == "Credits" else format_cost(avg_credits_per_request, cost_per_credit)
            st.metric(f"Avg {'Credits' if display_mode == 'Credits' else 'Cost'}/Request", display_value)
        
        # Usage over time chart
        st.markdown("#### ðŸ“ˆ Usage Over Time")
        if len(usage_data) > 1:
            # Prepare chart data based on display mode
            chart_data = usage_data.copy()
            if display_mode == "Estimated Cost":
                chart_data['DISPLAY_VALUES'] = chart_data['CREDITS'] * cost_per_credit
                y_column = 'DISPLAY_VALUES'
                title = "Cortex Analyst Cost Over Time"
            else:
                chart_data['DISPLAY_VALUES'] = chart_data['CREDITS']
                y_column = 'DISPLAY_VALUES'
                title = "Cortex Analyst Credits Over Time"
            
            fig = px.line(
                chart_data,
                x='START_TIME',
                y=y_column,
                title=title,
                color_discrete_sequence=['#29B5E8']
            )
            fig.update_layout(
                xaxis_title="Time",
                yaxis_title="Credits Used" if display_mode == "Credits" else "Estimated Cost ($)",
                font_family="Arial"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Detailed usage table
        st.markdown("#### ðŸ“‹ Detailed Usage History")
        display_usage = usage_data.copy()
        if display_mode == "Estimated Cost":
            display_usage['ESTIMATED_COST'] = display_usage['CREDITS'].apply(lambda x: format_cost(x, cost_per_credit))
        else:
            display_usage['CREDITS'] = display_usage['CREDITS'].apply(format_credits)
        
        st.dataframe(display_usage, use_container_width=True, hide_index=True)
    else:
        st.info(f"ðŸ’¡ No Cortex Analyst usage found for the last {period_days} days.")

# Raw Requests Data Tab  
with tab6:
    st.markdown("### ðŸ“‹ Cortex Analyst Requests Raw Data")
    
    period_days = st.selectbox("Select Time Period:", [7, 1, 3, 30], index=0, key="requests_period")
    requests_data = get_cortex_analyst_requests(period_days)
    
    if not requests_data.empty:
        st.write(f"**Total Requests:** {len(requests_data):,}")
        st.write(f"**Date Range:** Last {period_days} days")
        
        # Summary by semantic model
        st.markdown("#### ðŸ“Š Requests by Semantic Model")
        semantic_col = None
        for col in ['semantic_model_name', 'SEMANTIC_MODEL_NAME']:
            if col in requests_data.columns:
                semantic_col = col
                break
        
        if semantic_col and not requests_data[semantic_col].isna().all():
            model_summary = requests_data[requests_data[semantic_col].notna()].groupby([semantic_col]).size().reset_index(name='REQUEST_COUNT')
            model_summary = model_summary.sort_values('REQUEST_COUNT', ascending=False)
            st.dataframe(model_summary, use_container_width=True, hide_index=True)
        else:
            st.info("No semantic model data available.")
        
        # Summary by user
        st.markdown("#### ðŸ‘¤ Requests by User")
        user_col = None
        for col in ['user_name', 'USER_NAME']:
            if col in requests_data.columns:
                user_col = col
                break
                
        if user_col and not requests_data[user_col].isna().all():
            user_summary = requests_data[requests_data[user_col].notna()].groupby([user_col]).size().reset_index(name='REQUEST_COUNT')
            user_summary = user_summary.sort_values('REQUEST_COUNT', ascending=False)
            st.dataframe(user_summary, use_container_width=True, hide_index=True)
        else:
            st.info("No user data available.")
        
        # Raw requests table
        st.markdown("#### ðŸ“‹ Raw Requests Data")
        st.dataframe(requests_data, use_container_width=True, hide_index=True)
    else:
        st.info(f"ðŸ’¡ No Cortex Analyst requests found for the last {period_days} days.")

# Footer
st.markdown("---")
st.markdown(f"""
<div style="text-align: center; color: #666; font-size: 0.9rem;">
    <p>ðŸ’¡ <strong>Tip:</strong> Costs include warehouse execution (queries with 'Generated by Cortex Analyst') and Cortex Analyst text-to-SQL generation.</p>
    <p>ðŸ“Š Cost estimates based on {edition} edition (${cost_per_credit:.2f}/credit). Actual costs may vary.</p>
    <p>ðŸ•’ Data is sourced from ACCOUNT_USAGE views with up to 3-hour latency.</p>
</div>
""", unsafe_allow_html=True)